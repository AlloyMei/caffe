<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>
      Caffe 
    </title>

    <link rel="stylesheet" href="stylesheets/reset.css">
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46255508-1', 'daggerfs.com');
    ga('send', 'pageview');
  </script>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="index.html">Caffe</a></h1>
        <!-- <p class="header">Convolutional Architecture for Fast Feature Embedding</p> -->

        <ul>
          <!--<li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/tarball/master">Download TAR</a></li>-->
          <li><a class="buttons github" href="https://github.com/BVLC/caffe">View On GitHub</a></li>
        </ul>
        <p class="header">Maintained by<br><a class="header name" href="http://bvlc.eecs.berkeley.edu/">BVLC</a></p>
        <p class="header">Created by<br><a class="header name" href="http://daggerfs.com/">Yangqing Jia</a></p>

      </header>
      <section>

      <h1 id="caffe">Caffe</h1>

<p>Caffe is a deep learning framework developed with cleanliness, readability, and speed in mind.
It was created by <a href="http://daggerfs.com">Yangqing Jia</a>, and is in active development by the Berkeley Vision and Learning Center (<a href="http://bvlc.eecs.berkeley.edu">BVLC</a>) and by community contributors.
Caffe is released under the <a href="https://github.com/BVLC/caffe/blob/master/LICENSE">BSD 2-Clause license</a>.</p>

<h2 id="why">Why</h2>

<p><strong>Clean architecture</strong> enables rapid deployment.
Networks are specified in simple config files, with no hard-coded parameters in the code.
Switching between CPU and GPU code is as simple as setting a flag – so models can be trained on a GPU machine, and then used on commodity clusters.</p>

<p><strong>Readable &amp; modifiable implementation</strong> fosters active development.
In Caffe’s first six months, it has been forked by over 300 developers on Github, and many have contributed significant changes.</p>

<p><strong>Speed</strong> makes Caffe perfect for industry use.
Caffe can process over <strong>40M images per day</strong> with a single NVIDIA K40 or Titan GPU*.
That’s 5 ms/image in training, and 2 ms/image in test.
We believe that Caffe is the fastest CNN implementation available.</p>

<p><strong>Community</strong>: Caffe already powers academic research projects, startup prototypes, and even large-scale industrial applications in vision, speech, and multimedia.
There is an active discussion and support community on <a href="https://github.com/BVLC/caffe/issues">Github</a>.</p>

<p class="footnote">
* When files are properly cached, and using the ILSVRC2012-winning <a href="http://www.image-net.org/challenges/LSVRC/2012/supervision.pdf">SuperVision</a> model.
Consult performance <a href="/performance_hardware.html">details</a>.
</p>

<h2 id="how">How</h2>

<ul>
  <li><a href="https://www.dropbox.com/s/10fx16yp5etb8dv/caffe-presentation.pdf">Introductory slides</a>: slides about the Caffe architecture, <em>updated 03/14</em>.</li>
  <li><a href="http://ucb-icsi-vision-group.github.io/caffe-paper/caffe.pdf">ACM MM paper</a>: a 4-page report for the ACM Multimedia Open Source competition.</li>
  <li><a href="/installation.html">Installation instructions</a>: tested on Ubuntu, Red Hat, OS X.</li>
  <li><a href="/getting_pretrained_models.html">Pre-trained models</a>: BVLC provides ready-to-use models for non-commercial use.</li>
  <li><a href="/development.html">Development</a>: Guidelines for development and contributing to Caffe.</li>
</ul>

<h3 id="tutorials-and-examples">Tutorials and Examples</h3>

<ul>
  <li><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/imagenet_classification.ipynb">Image Classification [notebook]</a>: classify images with the pretrained ImageNet model by the Python interface.</li>
  <li><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/detection.ipynb">Detection [notebook]</a>: run a pretrained model as a detector in Python.</li>
  <li><a href="http://nbviewer.ipython.org/github/BVLC/caffe/blob/master/examples/filter_visualization.ipynb">Visualizing Features and Filters [notebook]</a>: extracting features and visualizing trained filters with an example image, viewed layer-by-layer.</li>
  <li><a href="/mnist.html">LeNet / MNIST Demo</a>: end-to-end training and testing of LeNet on MNIST.</li>
  <li><a href="/cifar10.html">CIFAR-10 Demo</a>: training and testing on the CIFAR-10 data.</li>
  <li><a href="/imagenet_training.html">Training ImageNet</a>: recipe for end-to-end training of an ImageNet classifier.</li>
  <li><a href="/feature_extraction.html">Feature extraction with C++</a>: feature extraction using pre-trained model.</li>
</ul>

<h2 id="citing-caffe">Citing Caffe</h2>

<p>Please cite Caffe in your publications if it helps your research:</p>

<pre><code>@misc{Jia13caffe,
   Author = {Yangqing Jia},
   Title = { {Caffe}: An Open Source Convolutional Architecture for Fast Feature Embedding},
   Year  = {2013},
   Howpublished = {\url{http://caffe.berkeleyvision.org/}
}
</code></pre>

<p>If you do publish a paper where Caffe helped your research, we encourage you to update the <a href="https://github.com/BVLC/caffe/wiki/Publications">publications wiki</a>.
Citations are also tracked automatically by <a href="http://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17333247995453974016">Google Scholar</a>.</p>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>Yangqing would like to thank the NVIDIA Academic program for providing GPUs, <a href="http://www1.icsi.berkeley.edu/~vinyals/">Oriol Vinyals</a> for discussions along the journey, and BVLC PI <a href="http://www.eecs.berkeley.edu/~trevor/">Trevor Darrell</a> for guidance.</p>

<p>A core set of BVLC members have contributed much new functionality and many fixes since the original release (alphabetical by first name):
<a href="https://github.com/erictzeng">Eric Tzeng</a>, <a href="http://imaginarynumber.net/">Evan Shelhamer</a>, <a href="http://jeffdonahue.com/">Jeff Donahue</a>, <a href="https://github.com/longjon">Jon Long</a>, <a href="http://www.cs.berkeley.edu/~rbg/">Ross Girshick</a>, <a href="http://sergeykarayev.com/">Sergey Karayev</a>, <a href="http://www.eecs.berkeley.edu/~sguada/">Sergio Guadarrama</a>.</p>

<p>Additionally, the open-source community plays a large and growing role in Caffe’s development.
Check out the Github <a href="https://github.com/BVLC/caffe/pulse">project pulse</a> for recent activity, and the <a href="https://github.com/BVLC/caffe/graphs/contributors">contributors</a> for a sorted list.</p>

<p>We sincerely appreciate your interest and contributions!
If you’d like to contribute, please read the <a href="development.html">development guide</a>.</p>


      </section>
<!--       <footer>
        <p><small>Hosted on <a href="http://pages.github.com">GitHub Pages</a>.</small></p>
      </footer>
 -->
  </div>
  <!--[if !IE]><script>fixScale(document);</script><![endif]-->
  </body>
</html>
