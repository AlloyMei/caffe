<!doctype html>
<html>
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="chrome=1">
    <title>Caffe</title>

    <link rel="stylesheet" href="stylesheets/reset.css">
    <link rel="stylesheet" href="stylesheets/styles.css">
    <link rel="stylesheet" href="stylesheets/pygment_trac.css">
    <script src="javascripts/scale.fix.js"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <!--[if lt IE 9]>
    <script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
  </head>
  <body>
  <script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-46255508-1', 'daggerfs.com');
    ga('send', 'pageview');
  </script>
    <div class="wrapper">
      <header>
        <h1 class="header"><a href="index.html">Caffe</a></h1>
        <p class="header">Convolutional Architecture for Fast Feature Embedding</p>

        <ul>
          <!--<li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/zipball/master">Download ZIP</a></li>
          <li class="download"><a class="buttons" href="https://github.com/BVLC/caffe/tarball/master">Download TAR</a></li>-->
          <li><a class="buttons github" href="https://github.com/BVLC/caffe">View On GitHub</a></li>
        </ul>
        <p class="header">Maintained by<br><a class="header name" href="http://ucbvlc.org/">BVLC</a></p>
        <p class="header">Created by<br><a class="header name" href="http://daggerfs.com/">Yangqing Jia</a></p>

      </header>
      <section>

      <h1 id="pretrained_models">Pre-trained models</h1>

<p><a href="http://bvlc.eecs.berkeley.edu">BVLC</a> aims to provide a variety of high quality pre-trained models. Note that unlike Caffe itself, these models are licensed for <strong>academic research / non-commercial use only</strong>. If you have any questions, please get in touch with us.</p>

<p>This page will be updated as more models become available.</p>

<h3 id="imagenet">ImageNet</h3>

<p><strong>Caffe Reference ImageNet Model</strong>: Our reference implementation of an ImageNet model trained on ILSVRC-2012 can be downloaded (232.6MB) by running <code>examples/imagenet/get_caffe_reference_imagenet_model.sh</code> from the Caffe root directory.</p>

<ul>
<li>The bundled model is the iteration 310,000 snapshot.</li>

<li>The best validation performance during training was iteration 313,000 with validation accuracy 57.412% and loss 1.82328.</li>
</ul>

<p><strong>AlexNet</strong>: Our training of the Krizhevsky architecture, which differs from the paperâ€™s methodology by (1) not training with the relighting data-augmentation and (2) initializing non-zero biases to 0.1 instead of 1. (2) was found necessary for training, as initialization to 1 gave flat loss. Download the model (243.9MB) by running <code>examples/imagenet/get_caffe_alexnet_model.sh</code> from the Caffe root directory.</p>

<ul>
<li>The bundled model is the iteration 360,000 snapshot.</li>

<li>The best validation performance during training was iteration 358,000 with validation accuracy 57.258% and loss 1.83948.</li>
</ul>

<p>Additionally, you will probably eventually need some auxiliary data (mean image, synset list, etc.): run <code>data/ilsvrc12/get_ilsvrc_aux.sh</code> from the root directory to obtain it.</p>

      </section>
      <footer>
        <p><small>Hosted on <a href="http://pages.github.com">GitHub Pages</a>.</small></p>
      </footer>
    </div>
    <!--[if !IE]><script>fixScale(document);</script><![endif]-->
  </body>
</html>
